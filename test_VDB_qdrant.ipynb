{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcda71e9",
   "metadata": {},
   "source": [
    "Cell 1 ‚Äî Setup + Connessione Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b16317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Filter\n",
    "\n",
    "# --- Config (adatta se serve) ---\n",
    "QDRANT_HOST = os.getenv(\"QDRANT_HOST\", \"127.0.0.1\")\n",
    "QDRANT_PORT = int(os.getenv(\"QDRANT_PORT\", \"6333\"))\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"financial_docs\")\n",
    "\n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "\n",
    "# sanity check\n",
    "info = client.get_collection(QDRANT_COLLECTION)\n",
    "info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95c009",
   "metadata": {},
   "source": [
    "Cell 2 ‚Äî Utilities: campionamento embedding da Qdrant\n",
    "\n",
    "Questa cell preleva un campione casuale di N vettori dalla collection (via scroll), con possibilit√† di filtro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_vectors_from_qdrant(\n",
    "    client: QdrantClient,\n",
    "    collection: str,\n",
    "    n: int = 30,\n",
    "    qdrant_filter: Filter | None = None,\n",
    "    seed: int = 42,\n",
    "    scroll_page_size: int = 256,\n",
    "    max_scroll_pages: int = 200,\n",
    "    with_payload: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Campiona n punti dalla collection Qdrant usando scroll.\n",
    "    Nota: scroll non √® 'random' nativo; qui raccogliamo un pool e poi campioniamo.\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    points_pool = []\n",
    "    offset = None\n",
    "    pages = 0\n",
    "\n",
    "    while pages < max_scroll_pages and len(points_pool) < max(n * 10, 300):\n",
    "        page, offset = client.scroll(\n",
    "            collection_name=collection,\n",
    "            scroll_filter=qdrant_filter,\n",
    "            limit=scroll_page_size,\n",
    "            with_vectors=True,\n",
    "            with_payload=with_payload,\n",
    "            offset=offset,\n",
    "        )\n",
    "        pages += 1\n",
    "        if not page:\n",
    "            break\n",
    "        points_pool.extend(page)\n",
    "\n",
    "        if offset is None:\n",
    "            break\n",
    "\n",
    "    if len(points_pool) < n:\n",
    "        raise ValueError(f\"Pool troppo piccolo: trovati {len(points_pool)} punti, richiesti {n}.\")\n",
    "\n",
    "    sampled = rng.sample(points_pool, n)\n",
    "\n",
    "    # vettori in matrice NxD\n",
    "    X = np.array([p.vector for p in sampled], dtype=np.float32)\n",
    "\n",
    "    # payload opzionale (utile per debug)\n",
    "    payloads = [p.payload if with_payload else None for p in sampled]\n",
    "    ids = [p.id for p in sampled]\n",
    "\n",
    "    return X, ids, payloads\n",
    "\n",
    "\n",
    "# --- ESEMPIO: campiona 30 vettori senza filtri ---\n",
    "X, ids, payloads = sample_vectors_from_qdrant(client, QDRANT_COLLECTION, n=30, seed=7)\n",
    "X.shape, ids[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e59c2",
   "metadata": {},
   "source": [
    "Cell 2-bis ‚Äî Normalizzazione L2 (NUOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(X, eps=1e-12):\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X / (norms + eps)\n",
    "\n",
    "# embedding originali (RAW)\n",
    "X_raw = X.copy()\n",
    "\n",
    "# embedding normalizzati (L2)\n",
    "X_l2 = l2_normalize(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc3785",
   "metadata": {},
   "source": [
    "Cell 3 ‚Äî Distanze (coseno, euclidea, chebyshev, minkowski, manhattan)\n",
    "\n",
    "Implementazione solo NumPy (niente SciPy richiesto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_matrix(X: np.ndarray, metric: str, p: float = 3.0, eps: float = 1e-12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ritorna matrice NxN delle distanze per la metrica richiesta.\n",
    "    metric: 'cosine' | 'euclidean' | 'chebyshev' | 'minkowski' | 'manhattan'\n",
    "    p: usato solo per minkowski\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if metric == \"cosine\":\n",
    "        # cosine distance = 1 - cosine similarity\n",
    "        norms = np.linalg.norm(X, axis=1, keepdims=True) + eps\n",
    "        Xn = X / norms\n",
    "        sim = Xn @ Xn.T\n",
    "        D = 1.0 - sim\n",
    "        np.fill_diagonal(D, 0.0)\n",
    "        return D\n",
    "\n",
    "    # per Lp: usa broadcasting Nx1xD - 1xNxD\n",
    "    diff = X[:, None, :] - X[None, :, :]\n",
    "\n",
    "    if metric == \"euclidean\":\n",
    "        D = np.sqrt(np.sum(diff * diff, axis=2))\n",
    "    elif metric == \"manhattan\":\n",
    "        D = np.sum(np.abs(diff), axis=2)\n",
    "    elif metric == \"chebyshev\":\n",
    "        D = np.max(np.abs(diff), axis=2)\n",
    "    elif metric == \"minkowski\":\n",
    "        D = np.sum(np.abs(diff) ** p, axis=2) ** (1.0 / p)\n",
    "    else:\n",
    "        raise ValueError(f\"Metrica non supportata: {metric}\")\n",
    "\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbf063",
   "metadata": {},
   "source": [
    "Cell 4 ‚Äî Indici di omogeneit√† (compattezza) del campione\n",
    "\n",
    "Qui calcoliamo pi√π indicatori per ogni metrica:\n",
    "\n",
    "A) Pairwise dispersion (solo distanze tra punti)\n",
    "\n",
    "mean_pairwise, median_pairwise\n",
    "\n",
    "std_pairwise, cv_pairwise (std/mean)\n",
    "\n",
    "iqr_pairwise (robustezza)\n",
    "\n",
    "p95_pairwise, max_pairwise\n",
    "\n",
    "%_under_median+MAD (proxy di ‚Äúdensit√†‚Äù robusta)\n",
    "\n",
    "B) Centroid dispersion (distanza di ogni punto dal centroide)\n",
    "\n",
    "mean_to_centroid, std_to_centroid, p95_to_centroid, max_to_centroid\n",
    "\n",
    "radius_ratio = p95/max (pi√π vicino a 1 ‚áí coda meno estrema; pi√π basso ‚áí outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010e34d",
   "metadata": {},
   "source": [
    "def robust_stats_1d(v: np.ndarray) -> dict:\n",
    "    v = np.asarray(v, dtype=np.float64)\n",
    "    v = v[np.isfinite(v)]\n",
    "    if v.size == 0:\n",
    "        return {}\n",
    "\n",
    "    q25, q50, q75 = np.percentile(v, [25, 50, 75])\n",
    "    iqr = q75 - q25\n",
    "    mad = np.median(np.abs(v - q50))  # Median Absolute Deviation\n",
    "\n",
    "    return {\n",
    "        \"count\": int(v.size),\n",
    "        \"mean\": float(np.mean(v)),\n",
    "        \"median\": float(q50),\n",
    "        \"std\": float(np.std(v, ddof=1)) if v.size > 1 else 0.0,\n",
    "        \"min\": float(np.min(v)),\n",
    "        \"max\": float(np.max(v)),\n",
    "        \"p95\": float(np.percentile(v, 95)),\n",
    "        \"iqr\": float(iqr),\n",
    "        \"mad\": float(mad),\n",
    "    }\n",
    "\n",
    "\n",
    "def homogeneity_indices(X: np.ndarray, metric: str, p: float = 3.0) -> dict:\n",
    "    \"\"\"\n",
    "    Calcola indici di omogeneit√†/compattezza per un campione di embedding.\n",
    "    \"\"\"\n",
    "    D = pairwise_distance_matrix(X, metric=metric, p=p)\n",
    "    n = D.shape[0]\n",
    "\n",
    "    # estrai solo triangolo superiore (distanze uniche)\n",
    "    tri = D[np.triu_indices(n, k=1)]\n",
    "    pw = robust_stats_1d(tri)\n",
    "\n",
    "    # centroid dispersion\n",
    "    C = np.mean(X, axis=0, keepdims=True)\n",
    "    Dc = pairwise_distance_matrix(np.vstack([X, C]), metric=metric, p=p)  # (n+1)x(n+1)\n",
    "    dist_to_centroid = Dc[:-1, -1]\n",
    "    cd = robust_stats_1d(dist_to_centroid)\n",
    "\n",
    "    # indicatori sintetici\n",
    "    mean_pw = pw[\"mean\"]\n",
    "    std_pw = pw[\"std\"]\n",
    "    cv_pw = (std_pw / mean_pw) if mean_pw > 0 else np.nan\n",
    "\n",
    "    # proxy densit√† robusta: quota sotto (median + MAD)\n",
    "    thr = pw[\"median\"] + pw[\"mad\"]\n",
    "    dense_ratio = float(np.mean(tri <= thr))\n",
    "\n",
    "    radius_ratio = (cd[\"p95\"] / cd[\"max\"]) if cd[\"max\"] > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"minkowski_p\": p if metric == \"minkowski\" else None,\n",
    "\n",
    "        # Pairwise\n",
    "        \"mean_pairwise\": mean_pw,\n",
    "        \"median_pairwise\": pw[\"median\"],\n",
    "        \"std_pairwise\": std_pw,\n",
    "        \"cv_pairwise\": cv_pw,\n",
    "        \"iqr_pairwise\": pw[\"iqr\"],\n",
    "        \"p95_pairwise\": pw[\"p95\"],\n",
    "        \"max_pairwise\": pw[\"max\"],\n",
    "        \"dense_ratio_(<=median+MAD)\": dense_ratio,\n",
    "\n",
    "        # To centroid\n",
    "        \"mean_to_centroid\": cd[\"mean\"],\n",
    "        \"std_to_centroid\": cd[\"std\"],\n",
    "        \"p95_to_centroid\": cd[\"p95\"],\n",
    "        \"max_to_centroid\": cd[\"max\"],\n",
    "        \"radius_ratio_(p95/max)\": radius_ratio,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb72b64",
   "metadata": {},
   "source": [
    "Cell 5 ‚Äî Esecuzione confronto metriche + tabella finale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4ed3c",
   "metadata": {},
   "source": [
    "rows = []\n",
    "\n",
    "# üîπ TEST SU EMBEDDING RAW\n",
    "for m, p in metrics:\n",
    "    if m == \"minkowski\":\n",
    "        r = homogeneity_indices(X_raw, metric=m, p=p)\n",
    "    else:\n",
    "        r = homogeneity_indices(X_raw, metric=m)\n",
    "    r[\"vector_space\"] = \"raw\"\n",
    "    rows.append(r)\n",
    "\n",
    "# üîπ TEST SU EMBEDDING L2-NORMALIZZATI\n",
    "for m, p in metrics:\n",
    "    if m == \"minkowski\":\n",
    "        r = homogeneity_indices(X_l2, metric=m, p=p)\n",
    "    else:\n",
    "        r = homogeneity_indices(X_l2, metric=m)\n",
    "    r[\"vector_space\"] = \"l2\"\n",
    "    rows.append(r)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ranking: pi√π basso = pi√π omogeneo (a parit√† di interpretazione)\n",
    "rank_cols = [\"mean_pairwise\", \"median_pairwise\", \"p95_pairwise\", \"mean_to_centroid\", \"p95_to_centroid\"]\n",
    "for c in rank_cols:\n",
    "    df[f\"rank_{c}\"] = df[c].rank(method=\"min\", ascending=True)\n",
    "\n",
    "df.sort_values(\"rank_mean_pairwise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell 6 ‚Äî Indici comparativi tra metriche (accordo tra matrici di distanza)\n",
    "\n",
    "Per capire quale distanza √® ‚Äúpi√π stabile/affidabile‚Äù anche in senso comparativo, √® utile misurare quanto cambia la struttura relativa del campione tra metriche:\n",
    "\n",
    "Correlazione Spearman tra le distanze pairwise (ranking delle coppie)\n",
    "\n",
    "Stress (MDS-like): quanto le distanze ‚Äúdeviamo‚Äù dalla metrica di riferimento dopo una semplice normalizzazione (z-score)\n",
    "\n",
    "KNN-overlap: quanto sono consistenti i vicini pi√π prossimi al variare della metrica (molto utile per retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_corr(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    # Spearman = Pearson sui ranghi\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    ra = pd.Series(a).rank().to_numpy()\n",
    "    rb = pd.Series(b).rank().to_numpy()\n",
    "    ra = ra - ra.mean()\n",
    "    rb = rb - rb.mean()\n",
    "    denom = (np.sqrt(np.sum(ra**2)) * np.sqrt(np.sum(rb**2)))\n",
    "    return float(np.sum(ra * rb) / denom) if denom > 0 else np.nan\n",
    "\n",
    "\n",
    "def zscore(v: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    v = np.asarray(v, dtype=np.float64)\n",
    "    mu = np.mean(v)\n",
    "    sd = np.std(v) + eps\n",
    "    return (v - mu) / sd\n",
    "\n",
    "\n",
    "def knn_sets(D: np.ndarray, k: int = 5):\n",
    "    # ritorna lista di set dei k vicini per ogni punto\n",
    "    n = D.shape[0]\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        idx = np.argsort(D[i])\n",
    "        idx = idx[idx != i][:k]\n",
    "        out.append(set(idx.tolist()))\n",
    "    return out\n",
    "\n",
    "\n",
    "def knn_overlap_score(D1: np.ndarray, D2: np.ndarray, k: int = 5) -> float:\n",
    "    A = knn_sets(D1, k=k)\n",
    "    B = knn_sets(D2, k=k)\n",
    "    overlaps = []\n",
    "    for s1, s2 in zip(A, B):\n",
    "        overlaps.append(len(s1.intersection(s2)) / k)\n",
    "    return float(np.mean(overlaps))\n",
    "\n",
    "\n",
    "# --- costruiamo tutte le matrici di distanza ---\n",
    "X_for_comparison = X_l2\n",
    "dist_mats = {}\n",
    "for m, p in metrics:\n",
    "    key = f\"{m}(p={p})\" if m == \"minkowski\" else m\n",
    "    dist_mats[key] = pairwise_distance_matrix(X_for_comparison, metric=m, p=(p or 3.0))\n",
    "\n",
    "\n",
    "# --- scegli una \"reference\" (spesso cosine, se la retrieval in Qdrant usa cosine) ---\n",
    "ref_key = \"cosine\"\n",
    "Dref = dist_mats[ref_key]\n",
    "n = Dref.shape[0]\n",
    "ref_tri = Dref[np.triu_indices(n, 1)]\n",
    "\n",
    "comp_rows = []\n",
    "for key, D in dist_mats.items():\n",
    "    tri = D[np.triu_indices(n, 1)]\n",
    "\n",
    "    # Spearman vs ref (confronto del ranking delle coppie)\n",
    "    sp = spearman_corr(ref_tri, tri)\n",
    "\n",
    "    # Stress: distanza tra versioni z-scored (non perfetto, ma indicatore pratico)\n",
    "    stress = float(np.sqrt(np.mean((zscore(ref_tri) - zscore(tri))**2)))\n",
    "\n",
    "    # KNN overlap\n",
    "    knn5 = knn_overlap_score(Dref, D, k=5)\n",
    "    knn10 = knn_overlap_score(Dref, D, k=10)\n",
    "\n",
    "    comp_rows.append({\n",
    "        \"metric\": key,\n",
    "        \"spearman_vs_ref\": sp,\n",
    "        \"stress_vs_ref_(zscore_rmse)\": stress,\n",
    "        \"knn_overlap@5_vs_ref\": knn5,\n",
    "        \"knn_overlap@10_vs_ref\": knn10,\n",
    "    })\n",
    "\n",
    "df_comp = pd.DataFrame(comp_rows).sort_values([\"spearman_vs_ref\", \"knn_overlap@10_vs_ref\"], ascending=False)\n",
    "df_comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4081f0",
   "metadata": {},
   "source": [
    "Cell 7 ‚Äî Plot (facoltativo) per visualizzare dispersione per metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a825f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pairwise_distributions(dist_mats: dict):\n",
    "    n = next(iter(dist_mats.values())).shape[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for name, D in dist_mats.items():\n",
    "        tri = D[np.triu_indices(n, 1)]\n",
    "        tri = tri[np.isfinite(tri)]\n",
    "        plt.hist(tri, bins=25, alpha=0.4, label=name)\n",
    "    plt.title(\"Distribuzione distanze pairwise (triangolo superiore)\")\n",
    "    plt.xlabel(\"distanza\")\n",
    "    plt.ylabel(\"frequenza\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_pairwise_distributions(dist_mats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3b4b2",
   "metadata": {},
   "source": [
    "Quali ‚Äúindici di bont√†‚Äù ti consiglio per scegliere la metrica?\n",
    "\n",
    "Quando dici ‚Äúmigliore per calcolare l‚Äôomogeneit√†‚Äù di 30 embedding, di solito vuoi una metrica che:\n",
    "\n",
    "separa bene un campione compatto da uno meno compatto\n",
    "‚Üí usa: mean/median/p95 pairwise, mean/p95 to centroid\n",
    "\n",
    "non venga dominata da outlier / code estreme\n",
    "‚Üí usa: IQR, MAD, radius_ratio (p95/max), e confronta p95 vs max\n",
    "\n",
    "sia stabile rispetto al concetto operativo (retrieval / ranking)\n",
    "‚Üí usa: KNN overlap e Spearman (se Qdrant lavora in cosine, confronta vs cosine come reference)\n",
    "\n",
    "Se vuoi un criterio ‚Äúone-liner‚Äù pratico, puoi creare uno score composito (basso=meglio), ad esempio:\n",
    "\n",
    "score = 0.5 * z(mean_pairwise) + 0.3 * z(p95_pairwise) + 0.2 * z(cv_pairwise)\n",
    "\n",
    "e poi, separatamente, guardare knn_overlap@10_vs_ref per capire quanto ‚Äúcambia‚Äù la neighborhood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
